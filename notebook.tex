
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Project\_Description}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{vehicle-detection-project}{%
\section{Vehicle Detection Project}\label{vehicle-detection-project}}

\hypertarget{the-goals-steps-of-this-project-are-the-following}{%
\subsection{The goals / steps of this project are the
following:}\label{the-goals-steps-of-this-project-are-the-following}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Perform a Histogram of Oriented Gradients (HOG) feature extraction on
  a labeled training set of images and train a classifier Linear SVM
  classifier
\item
  Optionally, you can also apply a color transform and append binned
  color features, as well as histograms of color, to your HOG feature
  vector.
\item
  Note: for those first two steps don't forget to normalize your
  features and randomize a selection for training and testing.
\item
  Implement a sliding-window technique and use your trained classifier
  to search for vehicles in images.
\item
  Run your pipeline on a video stream (start with the test\_video.mp4
  and later implement on full project\_video.mp4) and create a heat map
  of recurring detections frame by frame to reject outliers and follow
  detected vehicles.
\item
  Estimate a bounding box for vehicles detected.
\end{enumerate}

    \hypertarget{submission-includes}{%
\subsection{Submission Includes}\label{submission-includes}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{CarND-Vehicle-Detection.ipynb} - Python Notebook which
  contains all the code
\item
  \texttt{Readme} - Project writeup explainin how the rubric pointes
  were addressed and also other aspects of the project
\item
  \texttt{Project\_Output.mp4} - This contains the video output of the
  video. The video is also embedded in the \texttt{Readme} file as well
  as the \texttt{CarND-Vehicle-Detection.ipynb} notebook
\item
  \texttt{Project\_Output\_1.mp4} - This contains a second video output
  that was generated using information from previous frames. Although
  better at traking it has more false positives than the Earlier Video.
\item
  All the images used in the Readme File
\end{enumerate}

    \hypertarget{the-project-was-divided-into-two-parts}{%
\subsection{The project was divided into two
parts}\label{the-project-was-divided-into-two-parts}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Training a Classifier to distinguish between car and nor car images
\item
  Using this classifier to distinguish identify cars in a video Stream
\end{enumerate}

    \hypertarget{hog-features}{%
\subsection{HOG Features}\label{hog-features}}

This funciton is responsible for extracting the HOG Features. It was
implemented using the \texttt{get\_hog\_features} in the code

It takes an image as an input and also other factors such as the colour
spaces to be used, cells per block, pixels per cell as well as number of
orientations to classify the image into.

The hog parameters and how they were chosen is discussed in a cell
furhter down in this writeup as well as in the Python notebook attached

    \hypertarget{hog-visualization}{%
\subsection{Hog Visualization}\label{hog-visualization}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{image-preporcessing}{%
\subsection{Image preporcessing}\label{image-preporcessing}}

The Extract Features funtion in the code was created to pre process the
image

Different features from each image is extracted and used to make a
feature vector. This feature vector is a characteristic signature of the
image.

This feature vector is then passed to a classifier which looks at
signatures from car and non car images and then makes a decision on
which signatures represemt which class.

This funtion does the first part - extracting feature vectors from the
images

    \hypertarget{sliding-windows}{%
\subsection{Sliding windows}\label{sliding-windows}}

A sliding window approach is used to search for cars in different parts
of the image

Characteristics from these windows will be sent to the classifier to
identify cars. This has been implemented using the function
\texttt{slide\_window} in the code. This function along with the
\texttt{draw\ boxes} function is used to ultimately create sldiing
windows and search in them on the image. Examples and a more detailed
explaination is provided furhter down.

    \hypertarget{find-cars-function}{%
\subsection{Find cars function}\label{find-cars-function}}

A \texttt{find\_cars} function from the class was replicated.

The only variation made from the funciton in teh class material is that
I returned the rectangle coordinates. I had a lot of trouble with
handling arrays and plotting in this project. But also got to learn a
lot through this projeect.

This function identifies a bounding rectangle identifying the cars in
the frame

    \hypertarget{training-the-classifier}{%
\subsection{Training the classifier}\label{training-the-classifier}}

The classifier is trained in this step. The steps followed in this block
are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Feature vectors were extracted from the images based on the earlier
  funcitons.
\item
  Labels were created for these image as cars or no cars
\item
  The data was split into a training set and test set
\item
  A scaler transform based on the training data was then applied on both
  the training set and the test set
\item
  I chose a linear SVM as my classifier, I concentrated more on trying
  to obtain the right feature extraction thatn the classifier choice.
\item
  Different combinations for different feature extraction parameters
  were used.
\item
  The following excel snapshot shows the different models that were
  trained and also the accuracy obtained from each of them.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

Based on this the final combination of paramters I decided to go with
are as follows:

\texttt{color\_space\ =\ \textquotesingle{}YcrCb\textquotesingle{}}

\texttt{orient\ =\ 12\ \ \#\ HOG}

\texttt{pix\_per\_cell\ =\ 16}

\texttt{cell\_per\_block\ =\ 2}

\texttt{hog\_channel\ =\ "ALL"}

\texttt{Review\ 2} Added GridSearchCv to optimise the SVM Used. This
improved my accuracy drastically and helped identify cars much better

    The trained classifier was also tested on the test set yielding us an
accuracy of about 99\%

    \hypertarget{processing-the-image-through-the-pipeline}{%
\subsection{Processing the Image through the
pipeline}\label{processing-the-image-through-the-pipeline}}

Next steps were to now apply the other functions and actually use teh
classifier to identify cars in an image.

The steps followed were: 1. Deciding the size of the sliding window in
different portions of the screen 2. Extracting the Hog Features and
letting the calssifier identify cars 3. Create bounding boxes around the
cars and track them as they move across the frame.

    \hypertarget{looking-at-different-windows-used-for-searching}{%
\subsubsection{Looking at different windows used for
searching}\label{looking-at-different-windows-used-for-searching}}

    In the following cells you will see different areas in Y where different
sized boxes were used to search for images.

Smaller boxes were used to search for cars farther away, and larger
boxes were used to search ofr cars nearby.

It was also noted to not look at the part of the screen that has the
trees and the sky in it. Thus our search was limited from in the Y
coordinate between 400 and 700 in terms of coordinates.

Also at the same time boxes were overlapped to make sure different
aspects of the cars feature were captured by different boxes.

Further in the project we will see the concept of adding a heat map,
denoting the number of boxes that have selected a particualr area as a
car. Thus having overlapping boxes makes it easier to increase the heat
on detected cars and be able to identify them.

\hypertarget{inital-image}{%
\subsubsection{Inital Image}\label{inital-image}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{window-1}{%
\subsubsection{Window 1}\label{window-1}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

This is the smallest Window and thus is only used to search near the end
of the image (end of the area where we expect to detect cars)

    \hypertarget{window-2}{%
\subsubsection{Window 2}\label{window-2}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{window-3}{%
\subsubsection{Window 3}\label{window-3}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{window-4}{%
\subsubsection{Window 4}\label{window-4}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

This is the largest Window adn thus only searches near the car.

This is where teh sliding window function was used to search in
different sized boxes along different Y coordinates on the image. You
cna also see the classifications ont eh side showing which areas were
identified as cars

    \hypertarget{heat-map}{%
\subsubsection{Heat Map}\label{heat-map}}

This funtion was used to denote a heat map based on the rectanges and
their identification. This helped us define a threshold and remove a lot
of false positives from our detection.

Although a good method I was not able to completely eliminate the false
positives. I am not completely satisfied with the false positive
elimination but I belive give the methods used this is a pretty good
result.

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    Adding Threshold to the Heat Map

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    Funtion to draw boxes once the labels have been deduces

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{final-output}{%
\subsubsection{Final Output}\label{final-output}}

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

    \hypertarget{pipeline}{%
\subsection{Pipeline}\label{pipeline}}

This is the pipeline used for images. This is also the pipeline that has
been used to show most of the images that have been Printed in the
reports. It is just an aggregation of the steps we discussed aobve

\begin{figure}
\centering
\includegraphics{attachment:image.png}
\caption{image.png}
\end{figure}

This shows an evolution of the images along the pipeline

    \hypertarget{video-pipeline}{%
\subsection{Video Pipeline}\label{video-pipeline}}

This pipeline only takes an image as an input and return the final image
as the output.

I did struglle with how to input the Classifier and the X\_Scaler into
this funtion. Considering that I cannot keep training the classifier
everytime I call teh function. I was not able to identify a method but
when I did remove them fromt eh argument list all functions still seemed
to work. I need to look into this further but it does serve teh purpose
for now.

    \hypertarget{video-output}{%
\subsection{Video Output}\label{video-output}}

Please run the next cell to view the vide detecting the cars

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  I was able to reasonable detect the position of the cars with the
  bounding boxes jumping around a lot but always staying in or on the
  car.
\item
  One major issue si had was with the left yellow lane line. During the
  turns the calssifier was detecting it as a car and thus kept thorwing
  up false positives on it
\item
  Another area this model struggled was in the shadow when we pass unde
  the tree. At this point the model identifies the shadows as a car and
  thus leads to a few false positives.
\item
  Model also seemed to be more favourable in detecting Dark Coloured
  cars over light coloured ones. Need to explore if this could be
  because of a learning bias or a data bias that caused this. But the
  model did recognize the Black car much better tahtn teh white car.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{}Video Output}
        \PY{n}{project\PYZus{}output} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{project\PYZus{}output.mp4}\PY{l+s+s1}{\PYZsq{}}
        \PY{k+kn}{from} \PY{n+nn}{moviepy}\PY{n+nn}{.}\PY{n+nn}{editor} \PY{k}{import} \PY{n}{VideoFileClip}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}
        
        \PY{n}{HTML}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+s2}{\PYZlt{}video width=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{960}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ height=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{540}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ controls\PYZgt{}}
        \PY{l+s+s2}{  \PYZlt{}source src=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZgt{}}
        \PY{l+s+s2}{\PYZlt{}/video\PYZgt{}}
        \PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{project\PYZus{}output}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} <IPython.core.display.HTML object>
\end{Verbatim}
            
    \hypertarget{previous-frame-information}{%
\subsection{Previous Frame
information}\label{previous-frame-information}}

I tried an implementation to use information from previous frames. This
improved the recognition of the cars a lot and made their bounding boxes
very stable and almost always detecting cars throught the video.

But this came with its downsides with a significant increase in the
numbe rof false positives. This was an area I could not explore Furhter
nad hope to be able to do it sometime in the future.

\texttt{Review\ 2} I added the implementation to look at the previous
frames and use that information to improve teh current frame detection.
Although better at tracking the cars this methos did introduce more
false positives that the earlier one.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{}Video Output}
        \PY{n}{project\PYZus{}output} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Vehicle\PYZus{}detection\PYZus{}tracking\PYZus{}final\PYZus{}output.mp4}\PY{l+s+s1}{\PYZsq{}}
        \PY{k+kn}{from} \PY{n+nn}{moviepy}\PY{n+nn}{.}\PY{n+nn}{editor} \PY{k}{import} \PY{n}{VideoFileClip}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{HTML}
        
        \PY{n}{HTML}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+s2}{\PYZlt{}video width=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{960}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ height=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{540}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ controls\PYZgt{}}
        \PY{l+s+s2}{  \PYZlt{}source src=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}0\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZgt{}}
        \PY{l+s+s2}{\PYZlt{}/video\PYZgt{}}
        \PY{l+s+s2}{\PYZdq{}\PYZdq{}\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{project\PYZus{}output}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:} <IPython.core.display.HTML object>
\end{Verbatim}
            
    \hypertarget{challenges}{%
\subsection{Challenges}\label{challenges}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reasonable detection of the position of the car with the bounding
  boxes jumping around a lot but always staying in or on the car.
\item
  Lot of false positives ont he yellow lane line of the left - Also
  model detects the car very far away as well in teh beginnin gof the
  video thus marking up a huge portion of the lane line as well
\item
  Another area this model struggled was in the shadow when we pass under
  the tree. At this point the model identifies the shadows as a car and
  thus leads to a few false positives.
\item
  Very less time left for completion and thus the quality was a little
  bit compromised
\item
  Tried an implementation to use information from previous frames. This
  improved the recognition of the cars a lot and made their bounding
  boxes very stable and almost always detecting cars throught the video.
  But this came with its downsides with a significant increase in the
  number of false positives.
\end{enumerate}

\hypertarget{areas-of-improvement}{%
\subsection{Areas of Improvement}\label{areas-of-improvement}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using other feature vectors as well - Colour histogram adn Spatial
  Features
\item
  Use of Information form the previous frame to improve the data in the
  current frame
\item
  Applying the pipeline to more complicated videos with more cahllenges
  such as shadows and bridges
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
